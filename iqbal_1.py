# -*- coding: utf-8 -*-
"""iqbal_1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iqNywiD_-zGbJMuSF4yC1WiVJN7ezRWI
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = 'archive/data.xlsx'
data = pd.read_excel(file_path)

# Display the first few rows of the dataset to understand its structure
data.head()



from scipy import stats


# Step 1: Remove Missing Data
# Checking for any missing values in the dataset
missing_data = data.isnull().sum()

# Step 2: Outlier Removal
# Removing outliers using Z-score method for continuous variables
z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))
data_cleaned = data[(z_scores < 3).all(axis=1)]

# Displaying the result of missing data check and the shape of the dataset after outlier removal
missing_data, data_cleaned.shape



import matplotlib.pyplot as plt
import seaborn as sns

# Selecting continuous variables for plotting
continuous_vars = data_cleaned.select_dtypes(include=[np.number]).columns

# Plotting histograms for continuous variables
plt.figure(figsize=(20, 15))
for i, var in enumerate(continuous_vars):
    plt.subplot(6, 6, i + 1)
    sns.histplot(data_cleaned[var], kde=True, bins=20)
    plt.title(var)
    plt.tight_layout()

plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
import numpy as np

# Separating continuous and categorical variables
continuous_vars = data.select_dtypes(include=['float64', 'int64']).columns
categorical_vars = data.select_dtypes(include=['object']).columns

# Removing 'id' as it's just an identifier
continuous_vars = continuous_vars.drop('id')

# Calculating correlations among continuous variables
correlation_matrix = data[continuous_vars].corr()

# Calculating p-values for the correlations
p_values = pd.DataFrame(index=correlation_matrix.columns, columns=correlation_matrix.columns)

for row in correlation_matrix.columns:
    for col in correlation_matrix.columns:
        if row != col:
            corr_test = stats.pearsonr(data[row], data[col])
            p_values[row][col] = corr_test[1]
        else:
            p_values[row][col] = np.nan

# Plotting the correlation heatmap
high_corr = correlation_matrix[abs(correlation_matrix) > 0.75]
plt.figure(figsize=(12,10))
sns.heatmap(high_corr, annot=True, fmt=".2f")
plt.title("Correlation Heatmap of Continuous Variables")
plt.show()

# Plotting the p-values heatmap
plt.figure(figsize=(12,10))
sns.heatmap(p_values.astype(float), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("P-Value Heatmap of Correlation")
plt.show()

# Pair plots of continuous variables
sns.pairplot(data[continuous_vars])
plt.suptitle("Pair Plot of Continuous Variables", y=1.02)
plt.show()


# Calculating mean, variance, and 95% confidence interval of the mean variance
mean_variance = data[continuous_vars].var().mean()
mean_variance_ci_lower = mean_variance - 1.96 * stats.sem(data[continuous_vars].var())
mean_variance_ci_upper = mean_variance + 1.96 * stats.sem(data[continuous_vars].var())

mean_variance, mean_variance_ci_lower, mean_variance_ci_upper

# Performing Chi-square test and ANOVA for categorical variables
# Since we have only one categorical variable 'diagnosis', we'll perform ANOVA between 'diagnosis' and each continuous variable
anova_results = {}

for var in continuous_vars:
    group_data = [data[var][data['diagnosis'] == category] for category in data['diagnosis'].unique()]
    anova_results[var] = stats.f_oneway(*group_data)

anova_results

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd


# Data Preprocessing
data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})
X = data.drop('diagnosis', axis=1)
y = data['diagnosis']

# Standardizing the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=9014)

# Function to calculate specificity
def specificity(y_true, y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    return tn / (tn + fp)

# Models to train
models = {
    "Random Forest": RandomForestClassifier(random_state=9014),
    "Decision Tree": DecisionTreeClassifier(random_state=9014),
    "Naive Bayes": GaussianNB(),
    "Support Vector Machine": SVC(probability=True, random_state=9014),
    "Artificial Neural Network": MLPClassifier(max_iter=1000, random_state=9014),
    "Logistic Regression": LogisticRegression(random_state=9014)
}

# Training and evaluating models
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, "predict_proba") else [0] * len(y_pred)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    spec = specificity(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_proba)

    results[name] = [accuracy, precision, recall, spec, f1, auc]

# Results DataFrame
results_df = pd.DataFrame(results, index=['Accuracy', 'Precision', 'Recall', 'Specificity', 'F1 Score', 'AUC']).T

# Display the results
print(results_df.sort_values(by='Accuracy', ascending=False))

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# ... [previous code for loading data, preprocessing, and training models] ...

# Plotting ROC Curve for each model
plt.figure(figsize=(10, 8))

for name, model in models.items():
    # Predict probabilities
    if hasattr(model, "predict_proba"):
        y_proba = model.predict_proba(X_test)[:, 1]
    elif hasattr(model, "decision_function"):  # For SVM
        y_proba = model.decision_function(X_test)
    else:
        y_proba = [0] * len(y_test)

    # Compute ROC curve and AUC
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)

    # Plotting
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.50)')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic Curves')
plt.legend(loc='lower right')
plt.show()

